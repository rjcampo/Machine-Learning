{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Mini-Project 4\n",
    "### Richard Campo in collaboration with Julia Klauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries from scikit-learn for Support Vector Machine (SVM) classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Importing essential libraries for data manipulation and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Analysis\n",
    "### Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prtage       int64\n",
       "pesex       object\n",
       "ptdtrace    object\n",
       "pehspnon    object\n",
       "prcitshp    object\n",
       "peeduca     object\n",
       "vote        object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "prtage       int64\n",
       "pesex       object\n",
       "ptdtrace    object\n",
       "pehspnon    object\n",
       "prcitshp    object\n",
       "peeduca     object\n",
       "work        object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vote_df = pd.read_csv(\"vote.csv\")\n",
    "work_df = pd.read_csv(\"work.csv\")\n",
    "\n",
    "display(vote_df.dtypes)\n",
    "display(work_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.\n",
    "#### (a.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_mapper = {'flexible': 1, \"not flexible\": 0}\n",
    "vote_mapper = {'vote': 1, \"did not vote\": 0}\n",
    "\n",
    "work_df['work'] = work_df['work'].replace(work_mapper)\n",
    "vote_df['vote'] = vote_df['vote'].replace(vote_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NATIVE, BORN IN THE UNITED' 'FOREIGN BORN, U.S. CITIZEN BY'\n",
      " 'FOREIGN BORN, NOT A CITIZEN OF' 'NATIVE, BORN IN PUERTO RICO OR'\n",
      " 'NATIVE, BORN ABROAD OF']\n",
      "['NATIVE, BORN IN THE UNITED' 'FOREIGN BORN, U.S. CITIZEN BY'\n",
      " 'NATIVE, BORN IN PUERTO RICO OR' 'NATIVE, BORN ABROAD OF']\n",
      "prcitshp differences:  ['FOREIGN BORN, NOT A CITIZEN OF']\n"
     ]
    }
   ],
   "source": [
    "print(work_df.prcitshp.unique())\n",
    "print(vote_df.prcitshp.unique())\n",
    "\n",
    "# https://stackoverflow.com/a/25221271\n",
    "citshp_diff = np.setxor1d(work_df.prcitshp.unique(), vote_df.prcitshp.unique())\n",
    "\n",
    "print(\"prcitshp differences: \", citshp_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work data has a category \"FOREIGN BORN, NOT A CITIZEN OF\" that the vote data does not have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['White Only' 'Black Only' 'White-AI' 'Black-AI' 'Asian Only'\n",
      " 'White-Asian' 'Hawaiian/Pacific Islander Only' 'Asian-HP'\n",
      " 'White-Hawaiian' 'American Indian, Alaskan' 'White-Black' '2 or 3 Races'\n",
      " '4 or 5 Races']\n",
      "['White Only' 'Black Only' 'Hawaiian/Pacific Islander Only' 'Asian Only'\n",
      " 'American Indian, Alaskan' 'White-AI' 'Black-AI' 'W-B-AI' '2 or 3 Races'\n",
      " 'White-Asian' 'Asian-HP' 'White-Black' 'White-Hawaiian' 'W-A-HP'\n",
      " 'Black-Asian']\n",
      "ptdtrace differences:  ['4 or 5 Races' 'Black-Asian' 'W-A-HP' 'W-B-AI']\n"
     ]
    }
   ],
   "source": [
    "print(work_df.ptdtrace.unique())\n",
    "print(vote_df.ptdtrace.unique())\n",
    "\n",
    "race_diff = np.setxor1d(work_df.ptdtrace.unique(), vote_df.ptdtrace.unique())\n",
    "\n",
    "print(\"ptdtrace differences: \", race_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work data has a \"4 or 5 races\" category that the vote data does not have, and the vote data has categories for \"Black-Asian,\" \"W-A-HP,\" and \"W-B-AI\" that the work data does not have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c.) and (d.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "Index(['prtage', 'work', 'prcitshp_FOREIGN BORN, U.S. CITIZEN BY',\n",
      "       'prcitshp_NATIVE, BORN ABROAD OF',\n",
      "       'prcitshp_NATIVE, BORN IN PUERTO RICO OR',\n",
      "       'prcitshp_NATIVE, BORN IN THE UNITED', 'ptdtrace_2 or 3 Races',\n",
      "       'ptdtrace_4 or 5 Races', 'ptdtrace_American Indian, Alaskan',\n",
      "       'ptdtrace_Asian Only', 'ptdtrace_Asian-HP', 'ptdtrace_Black Only',\n",
      "       'ptdtrace_Black-AI', 'ptdtrace_Hawaiian/Pacific Islander Only',\n",
      "       'ptdtrace_White Only', 'ptdtrace_White-AI', 'ptdtrace_White-Asian',\n",
      "       'ptdtrace_White-Black', 'ptdtrace_White-Hawaiian', 'W-B-AI', 'W-A-HP',\n",
      "       'Black-Asian', 'pesex_MALE', 'pehspnon_NON-HISPANIC',\n",
      "       'peeduca_11TH GRADE', 'peeduca_12TH GRADE NO DIPLOMA',\n",
      "       'peeduca_1ST, 2ND, 3RD OR 4TH GRADE', 'peeduca_5TH OR 6TH GRADE',\n",
      "       'peeduca_7TH OR 8TH GRADE', 'peeduca_9TH GRADE',\n",
      "       'peeduca_ASSOCIATE DEGREE-ACADEMIC',\n",
      "       'peeduca_ASSOCIATE DEGREE-OCCUPATIONAL/', 'peeduca_BACHELOR'S DEGREE',\n",
      "       'peeduca_DOCTORATE DEGREE', 'peeduca_HIGH SCHOOL GRAD-DIPLOMA OR',\n",
      "       'peeduca_LESS THAN 1ST GRADE', 'peeduca_MASTER'S DEGREE (EX: MA, MS,',\n",
      "       'peeduca_PROFESSIONAL SCHOOL DEG',\n",
      "       'peeduca_SOME COLLEGE BUT NO DEGREE'],\n",
      "      dtype='object')\n",
      "39\n",
      "Index(['prtage', 'vote', 'prcitshp_NATIVE, BORN ABROAD OF',\n",
      "       'prcitshp_NATIVE, BORN IN PUERTO RICO OR',\n",
      "       'prcitshp_NATIVE, BORN IN THE UNITED',\n",
      "       'prcitshp_FOREIGN BORN, NOT A CITIZEN OF', 'ptdtrace_2 or 3 Races',\n",
      "       'ptdtrace_American Indian, Alaskan', 'ptdtrace_Asian Only',\n",
      "       'ptdtrace_Asian-HP', 'ptdtrace_Black Only', 'ptdtrace_Black-AI',\n",
      "       'ptdtrace_Black-Asian', 'ptdtrace_Hawaiian/Pacific Islander Only',\n",
      "       'ptdtrace_W-A-HP', 'ptdtrace_W-B-AI', 'ptdtrace_White Only',\n",
      "       'ptdtrace_White-AI', 'ptdtrace_White-Asian', 'ptdtrace_White-Black',\n",
      "       'ptdtrace_White-Hawaiian', '4 or 5 Races', 'pesex_MALE',\n",
      "       'pehspnon_NON-HISPANIC', 'peeduca_11TH GRADE',\n",
      "       'peeduca_12TH GRADE NO DIPLOMA', 'peeduca_1ST, 2ND, 3RD OR 4TH GRADE',\n",
      "       'peeduca_5TH OR 6TH GRADE', 'peeduca_7TH OR 8TH GRADE',\n",
      "       'peeduca_9TH GRADE', 'peeduca_ASSOCIATE DEGREE-ACADEMIC',\n",
      "       'peeduca_ASSOCIATE DEGREE-OCCUPATIONAL/', 'peeduca_BACHELOR'S DEGREE',\n",
      "       'peeduca_DOCTORATE DEGREE', 'peeduca_HIGH SCHOOL GRAD-DIPLOMA OR',\n",
      "       'peeduca_LESS THAN 1ST GRADE', 'peeduca_MASTER'S DEGREE (EX: MA, MS,',\n",
      "       'peeduca_PROFESSIONAL SCHOOL DEG',\n",
      "       'peeduca_SOME COLLEGE BUT NO DEGREE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "work_df = pd.get_dummies(work_df, columns=['prcitshp'], drop_first=True)\n",
    "vote_df = pd.get_dummies(vote_df, columns=['prcitshp'], drop_first=True)\n",
    "\n",
    "vote_df[\"prcitshp_FOREIGN BORN, NOT A CITIZEN OF\"] = 0\n",
    "\n",
    "work_df = pd.get_dummies(work_df, columns=['ptdtrace'])\n",
    "vote_df = pd.get_dummies(vote_df, columns=['ptdtrace'])\n",
    "\n",
    "vote_df['4 or 5 Races'] = 0\n",
    "work_df['W-B-AI'] = 0\n",
    "work_df['W-A-HP'] = 0\n",
    "work_df['Black-Asian'] = 0\n",
    "\n",
    "work_df = pd.get_dummies(work_df, columns=['pesex'], drop_first=True)\n",
    "vote_df = pd.get_dummies(vote_df, columns=['pesex'], drop_first=True)\n",
    "work_df = pd.get_dummies(work_df, columns=['pehspnon'], drop_first=True)\n",
    "vote_df = pd.get_dummies(vote_df, columns=['pehspnon'], drop_first=True)\n",
    "work_df = pd.get_dummies(work_df, columns=['peeduca'], drop_first=True)\n",
    "vote_df = pd.get_dummies(vote_df, columns=['peeduca'], drop_first=True)\n",
    "\n",
    "print(len(work_df.columns))\n",
    "print(work_df.columns)\n",
    "\n",
    "print(len(vote_df.columns))\n",
    "print(vote_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_work = work_df.drop('work', axis = 1)\n",
    "y_work = work_df['work']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_work_scaled = scaler.fit_transform(X_work)\n",
    "\n",
    "parameters = {'kernel': ('linear', 'poly', 'sigmoid'), 'C': [0.1, 1, 5, 10]}\n",
    "\n",
    "svc = SVC() \n",
    "cv = KFold(n_splits=5, random_state=26, shuffle=True)\n",
    "\n",
    "classifier = GridSearchCV(svc, parameters, cv=cv)\n",
    "\n",
    "classifier.fit(X_work_scaled, y_work);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "Error Rate: 0.13740000000000008\n",
      "Rank: 1\n",
      "\n",
      "Hyperparameters: {'C': 0.1, 'kernel': 'poly'}\n",
      "Error Rate: 0.36440000000000006\n",
      "Rank: 12\n",
      "\n",
      "Hyperparameters: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "Error Rate: 0.13859999999999995\n",
      "Rank: 5\n",
      "\n",
      "Hyperparameters: {'C': 1, 'kernel': 'linear'}\n",
      "Error Rate: 0.1379999999999999\n",
      "Rank: 2\n",
      "\n",
      "Hyperparameters: {'C': 1, 'kernel': 'poly'}\n",
      "Error Rate: 0.1774000000000001\n",
      "Rank: 11\n",
      "\n",
      "Hyperparameters: {'C': 1, 'kernel': 'sigmoid'}\n",
      "Error Rate: 0.16059999999999997\n",
      "Rank: 8\n",
      "\n",
      "Hyperparameters: {'C': 5, 'kernel': 'linear'}\n",
      "Error Rate: 0.1382\n",
      "Rank: 3\n",
      "\n",
      "Hyperparameters: {'C': 5, 'kernel': 'poly'}\n",
      "Error Rate: 0.1469999999999999\n",
      "Rank: 7\n",
      "\n",
      "Hyperparameters: {'C': 5, 'kernel': 'sigmoid'}\n",
      "Error Rate: 0.1754000000000001\n",
      "Rank: 9\n",
      "\n",
      "Hyperparameters: {'C': 10, 'kernel': 'linear'}\n",
      "Error Rate: 0.1382\n",
      "Rank: 3\n",
      "\n",
      "Hyperparameters: {'C': 10, 'kernel': 'poly'}\n",
      "Error Rate: 0.14540000000000008\n",
      "Rank: 6\n",
      "\n",
      "Hyperparameters: {'C': 10, 'kernel': 'sigmoid'}\n",
      "Error Rate: 0.17599999999999993\n",
      "Rank: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_sets = zip(\n",
    "    classifier.cv_results_[\"params\"], \n",
    "    classifier.cv_results_[\"mean_test_score\"], \n",
    "    classifier.cv_results_[\"rank_test_score\"]\n",
    "    )\n",
    "\n",
    "for params, mean_score, rank in hyperparameter_sets:\n",
    "     error_rate = 1 - mean_score\n",
    "     print(\"Hyperparameters:\", params)\n",
    "     print(\"Error Rate:\", error_rate)\n",
    "     print(\"Rank:\", rank)\n",
    "     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter set: {'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "best_params_index = np.argmax(classifier.cv_results_['mean_test_score'])\n",
    "\n",
    "best_params = classifier.cv_results_['params'][best_params_index]\n",
    "\n",
    "print(\"Best hyperparameter set:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters that give us the lowest error rate (highest mean test score) are $C = 0.1$ and a linear kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of best hyperparameters:  0.8626\n"
     ]
    }
   ],
   "source": [
    "best_params_index = np.argmax(classifier.cv_results_['mean_test_score'])\n",
    "\n",
    "best_accuracy = classifier.cv_results_['mean_test_score'][best_params_index]\n",
    "\n",
    "print(\"Accuracy score of best hyperparameters: \", \n",
    "      round(best_accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score we get from the model with the optimal hyperparameters is about 86.26%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean        0.680800\n",
       "std         0.466213\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: imputed_work, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc = SVC(C=5, kernel=\"poly\")\n",
    "\n",
    "best_svc.fit(X_work_scaled, y_work)\n",
    "\n",
    "X_vote = vote_df.drop(columns=\"vote\")\n",
    "y_vote = vote_df[\"vote\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_vote_scaled = scaler.fit_transform(X_vote)\n",
    "\n",
    "vote_df.loc[:,'imputed_work'] = best_svc.predict(X_vote_scaled)\n",
    "\n",
    "vote_df['imputed_work'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>vote</td>       <th>  R-squared:         </th> <td>   0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1515.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Mar 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:01:06</td>     <th>  Log-Likelihood:    </th> <td> -1636.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>   3283.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4995</td>      <th>  BIC:               </th> <td>   3315.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    1.4684</td> <td>    0.039</td> <td>   37.714</td> <td> 0.000</td> <td>    1.392</td> <td>    1.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>imputed_work</th> <td>    0.1988</td> <td>    0.017</td> <td>   11.410</td> <td> 0.000</td> <td>    0.165</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prtage</th>       <td>   -0.0325</td> <td>    0.001</td> <td>  -22.733</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prtage_sq</th>    <td>    0.0002</td> <td> 1.49e-05</td> <td>   11.041</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pesex_MALE</th>   <td>    0.0198</td> <td>    0.010</td> <td>    2.071</td> <td> 0.038</td> <td>    0.001</td> <td>    0.039</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>69.321</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  72.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.285</td> <th>  Prob(JB):          </th> <td>2.28e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.144</td> <th>  Cond. No.          </th> <td>2.49e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.49e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       vote       & \\textbf{  R-squared:         } &     0.548   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.548   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     1515.   \\\\\n",
       "\\textbf{Date:}             & Sat, 02 Mar 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     10:01:06     & \\textbf{  Log-Likelihood:    } &   -1636.5   \\\\\n",
       "\\textbf{No. Observations:} &        5000      & \\textbf{  AIC:               } &     3283.   \\\\\n",
       "\\textbf{Df Residuals:}     &        4995      & \\textbf{  BIC:               } &     3315.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}         &       1.4684  &        0.039     &    37.714  &         0.000        &        1.392    &        1.545     \\\\\n",
       "\\textbf{imputed\\_work} &       0.1988  &        0.017     &    11.410  &         0.000        &        0.165    &        0.233     \\\\\n",
       "\\textbf{prtage}        &      -0.0325  &        0.001     &   -22.733  &         0.000        &       -0.035    &       -0.030     \\\\\n",
       "\\textbf{prtage\\_sq}    &       0.0002  &     1.49e-05     &    11.041  &         0.000        &        0.000    &        0.000     \\\\\n",
       "\\textbf{pesex\\_MALE}   &       0.0198  &        0.010     &     2.071  &         0.038        &        0.001    &        0.039     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 69.321 & \\textbf{  Durbin-Watson:     } &    1.998  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   72.032  \\\\\n",
       "\\textbf{Skew:}          & -0.285 & \\textbf{  Prob(JB):          } & 2.28e-16  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.144 & \\textbf{  Cond. No.          } & 2.49e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.49e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   vote   R-squared:                       0.548\n",
       "Model:                            OLS   Adj. R-squared:                  0.548\n",
       "Method:                 Least Squares   F-statistic:                     1515.\n",
       "Date:                Sat, 02 Mar 2024   Prob (F-statistic):               0.00\n",
       "Time:                        10:01:06   Log-Likelihood:                -1636.5\n",
       "No. Observations:                5000   AIC:                             3283.\n",
       "Df Residuals:                    4995   BIC:                             3315.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            1.4684      0.039     37.714      0.000       1.392       1.545\n",
       "imputed_work     0.1988      0.017     11.410      0.000       0.165       0.233\n",
       "prtage          -0.0325      0.001    -22.733      0.000      -0.035      -0.030\n",
       "prtage_sq        0.0002   1.49e-05     11.041      0.000       0.000       0.000\n",
       "pesex_MALE       0.0198      0.010      2.071      0.038       0.001       0.039\n",
       "==============================================================================\n",
       "Omnibus:                       69.321   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               72.032\n",
       "Skew:                          -0.285   Prob(JB):                     2.28e-16\n",
       "Kurtosis:                       3.144   Cond. No.                     2.49e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.49e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_df.loc[:,\"prtage_sq\"] = np.power(vote_df[\"prtage\"], 2)\n",
    "\n",
    "X = vote_df[[\"imputed_work\", \"prtage\", \"prtage_sq\", \"pesex_MALE\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = vote_df[\"vote\"]\n",
    "\n",
    "result = sm.OLS(y, X).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we can see that our imputed work variable is predictive of whether an individual will vote. Since this is a linear probability model, we can interpret the estimated coefficient of `imputed_work` to mean that having a job with flexible work hours increases the predicted probability that an individual will vote by 19.88 percentage points holding age, age squared, and sex constant. This result is also statistically significant at the 5% level since the p-value is approximately 0. This means that we can reject the null hypothesis that a flexible work schedule has no predicted effect on voting in favor of the alternative hypothesis that the predicted effect of having a flexible work schedule on whether an individual votes is different from zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_vote_relationship = result.params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attenuation bias correction formula\n",
    "def compute_M(a,b):\n",
    "    return 1 / (1 - 2 * b) * (1 - (1 - b) * b / a - (1 - b) * b / (1 - a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6808\n"
     ]
    }
   ],
   "source": [
    "# For the value of a, find the proportion of imputed work schedules that are flexible\n",
    "a = sum(vote_df[\"imputed_work\"])/(vote_df[\"imputed_work\"].size)\n",
    "print(\"The value of a is: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1374\n"
     ]
    }
   ],
   "source": [
    "# For the value of b, use the cross-validation error rate \n",
    "b = round(1 - max(classifier.cv_results_['mean_test_score']), 4)\n",
    "print(\"The value of b is: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of M is:  0.6269\n"
     ]
    }
   ],
   "source": [
    "M = compute_M(a,b)\n",
    "print(\"The value of M is: \", round(M, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the value of $a$ is about 0.6808, the value of $b$ is about 0.1374, and the value of $M$ is about 0.6269."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3171\n"
     ]
    }
   ],
   "source": [
    "work_vote_bias_correction = work_vote_relationship / M\n",
    "print(round(work_vote_bias_correction, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias-corrected version of the estimated coefficient of `imputed_work` is 0.3171, which is larger than the uncorrected estimate of 0.1988 we found earlier. This indicates that the estimated effect of having a job with flexible hours on the predicted probability of voting is even larger than we estimated previously, so the estimate is still statistically significant at the 5% level. Now, the interpretation is that we predict that having a job with flexible hours increases the expected probability of voting by 31.71 percentage points according to our linear probability model, holding age, age squared, and sex constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
